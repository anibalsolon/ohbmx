{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-twitter python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import urllib\n",
    "import twitter\n",
    "import itertools\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "t = twitter.Api(consumer_key=os.getenv('CONSUMER_KEY'),\n",
    "                consumer_secret=os.getenv('CONSUMER_SECRET'),\n",
    "                access_token_key=os.getenv('ACCESS_TOKEN'),\n",
    "                access_token_secret=os.getenv('ACCESS_SECRET'),\n",
    "                tweet_mode='extended')\n",
    "\n",
    "def remove_starting_mentions(tw):\n",
    "    text = tw.full_text.strip()\n",
    "    for user in set([u.screen_name for u in tw.user_mentions]):\n",
    "        text = text.replace(f'@{user}', '', 1)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def parse_date(dt):\n",
    "    return datetime.datetime.strptime(dt, '%a %b %d %H:%M:%S %z %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = {}\n",
    "\n",
    "# https://twitter.com/ohbmequinox/status/1240818088376823809?s=21\n",
    "\n",
    "first_tweet = 1240818088376823809\n",
    "params      = {\n",
    "    'include_rts': False,\n",
    "    'count': 5000,\n",
    "    'since_id': first_tweet-1,\n",
    "}\n",
    "\n",
    "fetching= True\n",
    "while fetching:\n",
    "    fetching = t.GetUserTimeline(screen_name='ohbmequinox', **params)\n",
    "    tweets.update({tt.id: tt for tt in fetching})\n",
    "    if not fetching or first_tweet in [tt.id for tt in fetching]:\n",
    "        break\n",
    "    params = {'max_id': fetching[-1].id}\n",
    "    \n",
    "# https://twitter.com/AskDrJeg/status/1240855036873211904\n",
    "wrong_status = t.GetStatus(1240855036873211904)\n",
    "wrong_status.full_text = wrong_status.full_text.replace('@OHBMequinoX ', '', 1)\n",
    "wrong_status.user_mentions = wrong_status.user_mentions[1:]\n",
    "wrong_status.user = list(tweets.values())[0].user\n",
    "tweets.update({wrong_status.id: wrong_status})\n",
    "del tweets[1240854713781764101]\n",
    "\n",
    "# https://twitter.com/OHBMequinoX/status/1240823872976379904\n",
    "del tweets[1240823872976379904]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1240912684163334145: {'date': datetime.datetime(2020, 3, 20, 8, 6, 53, tzinfo=datetime.timezone.utc), 'text': 'It’s been an honour to bring you #OHBMx from Aus. @LeonieBorne\\n @KoussisNikitas\\n @AskDrJeg\\n @DrBreaky\\n @MegaEJ_Campbell\\n signing off. \\nThoughts are with our EU colleagues &amp; their families in this challenging time. \\nPls take a break before the EU Hub takes the helm.', 'ids': [1240912684163334145], 'mentions': [1228144941315936257, 1033212944832593920, 1135512246438678528, 3305807792, 1886474232]}}\n"
     ]
    }
   ],
   "source": [
    "originals = {twid: tw for twid, tw in tweets.items() if tw.retweeted_status is None}\n",
    "\n",
    "timeline = {\n",
    "    twid: {\n",
    "        'date': parse_date(tw.created_at),\n",
    "        'text': tw.full_text.strip(),\n",
    "        'ids': [twid],\n",
    "        'mentions': [u.id for u in tw.user_mentions],\n",
    "    }\n",
    "    for twid, tw in originals.items()\n",
    "    if tw.in_reply_to_status_id is None\n",
    "}\n",
    "\n",
    "print({k: t for k, t in timeline.items() if 'honour' in t['text']})\n",
    "\n",
    "originals_replies = {\n",
    "    twid: tw for twid, tw in originals.items()\n",
    "    if tw.in_reply_to_status_id and tw.in_reply_to_screen_name.lower() in ['ohbmequinox']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_to = {twid: twid for twid in timeline}\n",
    "\n",
    "while originals_replies:\n",
    "\n",
    "    for twid, tw in list(originals_replies.items()):\n",
    "        \n",
    "        twid_reply = tw.in_reply_to_status_id\n",
    "\n",
    "        if twid_reply not in timeline and twid_reply not in reply_to:\n",
    "            continue\n",
    "            \n",
    "        if twid_reply in reply_to:\n",
    "            twid_reply = reply_to[twid_reply]\n",
    "            \n",
    "        reply_to[twid] = twid_reply\n",
    "\n",
    "        original_text = timeline[twid_reply]['text']\n",
    "        text = remove_starting_mentions(tw)\n",
    "\n",
    "        for ellipsis in ['...', '…']:\n",
    "            if text.startswith(ellipsis):\n",
    "                text = text.replace(ellipsis, '', 1)\n",
    "            if original_text.endswith(ellipsis):\n",
    "                original_text = ellipsis.join(original_text.split(ellipsis)[:-1])\n",
    "\n",
    "        timeline[twid_reply]['text'] = f'{original_text} {text}'\n",
    "        \n",
    "        if twid_reply == 1240888314137202689:\n",
    "            timeline[twid_reply]['text'] = timeline[twid_reply]['text'].replace('1/2', '').replace('2/2', '')\n",
    "        \n",
    "        timeline[twid_reply]['ids'] += [twid]\n",
    "        timeline[twid_reply]['mentions'] += [u.id for u in tw.user_mentions]\n",
    "        \n",
    "        del originals_replies[twid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': datetime.datetime(2020, 3, 20, 8, 6, 53, tzinfo=datetime.timezone.utc),\n",
       " 'text': 'It’s been an honour to bring you #OHBMx from Aus. @LeonieBorne\\n @KoussisNikitas\\n @AskDrJeg\\n @DrBreaky\\n @MegaEJ_Campbell\\n signing off. \\nThoughts are with our EU colleagues &amp; their families in this challenging time. \\nPls take a break before the EU Hub takes the helm.',\n",
       " 'ids': [1240912684163334145],\n",
       " 'mentions': [1228144941315936257,\n",
       "  1033212944832593920,\n",
       "  1135512246438678528,\n",
       "  3305807792,\n",
       "  1886474232]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeline[1240912684163334145]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'id': twid,\n",
    "        'date': tw['date'],\n",
    "        'text': tw['text'],\n",
    "        'session': tw['text'].split('\\n')[0],\n",
    "    }\n",
    "    for twid, tw in timeline.items()\n",
    "    if tw['text'].startswith('#OHBMx-')\n",
    "]).sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('presentations.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = df[(df.session.str.contains('#keynote') | df.session.str.contains('#talk'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replies(tweets, mentions):\n",
    "    user = tweets[0].user.screen_name\n",
    "    tweet_ids = [tweet.id for tweet in tweets]\n",
    "    \n",
    "    max_id = None\n",
    "    while True:\n",
    "        try:\n",
    "            replies = t.GetSearch(\n",
    "                term=f'(to:@{user})',\n",
    "                since_id=min(tweet_ids),\n",
    "                max_id=max_id,\n",
    "                count=100,\n",
    "                result_type='recent'\n",
    "            )\n",
    "        except twitter.error.TwitterError as e:\n",
    "            print(\"Waiting\")\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "            \n",
    "        replied_tweets = []\n",
    "        for reply in replies:\n",
    "            \n",
    "            max_id = reply.id\n",
    "            \n",
    "            if reply.in_reply_to_status_id not in tweet_ids:\n",
    "                continue\n",
    "                \n",
    "            if reply.user.id not in mentions[reply.in_reply_to_status_id]:\n",
    "                continue\n",
    "                \n",
    "            mentions.update({\n",
    "                reply.id: mentions[reply.in_reply_to_status_id]\n",
    "            })\n",
    "                \n",
    "            yield reply\n",
    "            yield from get_replies([reply], mentions)\n",
    "            \n",
    "        if len(replies) != 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n",
      "Waiting\n"
     ]
    }
   ],
   "source": [
    "all_tweets_from_threads = []\n",
    "mentions_for_tweets_from_threads = {}\n",
    "for twid in threads.id.tolist():\n",
    "    all_tweets_from_threads += timeline[twid]['ids']\n",
    "    for subtwid in timeline[twid]['ids']:\n",
    "        mentions_for_tweets_from_threads[subtwid] = timeline[twid]['mentions']\n",
    "        \n",
    "replies = list(get_replies([tweets[twid] for twid in all_tweets_from_threads], mentions_for_tweets_from_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unthread(tweets, original_tweets, replies):\n",
    "    thread_replies = [\n",
    "        tw for tw in replies\n",
    "        if tw.in_reply_to_status_id in original_tweets and tw.id not in original_tweets\n",
    "    ]\n",
    "    if thread_replies:\n",
    "        yield from thread_replies\n",
    "        yield from unthread(tweets, [r.id for r in thread_replies], replies)\n",
    "\n",
    "for twid in timeline:\n",
    "    if twid not in all_tweets_from_threads:\n",
    "        continue\n",
    "        \n",
    "    timeline[twid]['thread'] = []\n",
    "    for rr in sorted(unthread(tweets, timeline[twid]['ids'], replies), key=lambda tw: (parse_date(tw.created_at))):\n",
    "        timeline[twid]['thread'] += [{\n",
    "            'id': str(rr.id),\n",
    "            'user': rr.user.screen_name,\n",
    "            'date': parse_date(rr.created_at),\n",
    "            'text': remove_starting_mentions(rr),\n",
    "            'media': rr.AsDict().get('media', []),\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = { **{twid: tw for twid, tw in tweets.items()}, **{r.id: r for r in replies} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data.json', 'w') as outfile:\n",
    "    json.dump(\n",
    "        {'tweets': sorted([d.AsDict() for d in data.values()], key=lambda t: parse_date(t['created_at']))},\n",
    "        outfile\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def dtconverter(o):\n",
    "    if isinstance(o, datetime.datetime):\n",
    "        return o.__str__()\n",
    " \n",
    "with open('timeline.json', 'w') as outfile:\n",
    "    json.dump(\n",
    "        {\n",
    "            'timeline': sorted([\n",
    "                { **t, 'ids': [str(twid) for twid in t['ids']]}\n",
    "                for t in timeline.values()\n",
    "            ], key=lambda t: t['date'])\n",
    "        },\n",
    "        outfile,\n",
    "        default=dtconverter\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
